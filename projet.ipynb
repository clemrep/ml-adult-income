{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70c21d4",
   "metadata": {},
   "source": [
    "# Adult Income Classification Project\n",
    "\n",
    "Le projet vise à analyser le jeu de données Adult Income afin d’identifier les différents facteurs qui influencent le niveau de revenu d'une personne et de construire un modèle capable de prédire si une personne gagne plus ou moins de 50 000 dollars par an. \n",
    "\n",
    "Le dataset, disponible dans plusieurs versions (UCI, OpenML, variantes nettoyées ou simplifiées), est ici utilisé dans sa version OpenML, qui offre un format homogène et des variables à la fois numériques et catégorielles. Notre problème sera approché sous la forme d'une classification binaire (+ ou - de 50k$/an de revenus) car le dataset ne contient pas la valeur exacte du revenu, qu'une catégorie.\n",
    "\n",
    "Ce notebook sera articulé en trois grandes parties :\n",
    "\n",
    "1. **Exploration des données (EDA) et analyses non supervisées**\n",
    "2. **Préprocessing des données et séparation des jeux d'apprentissage/test**\n",
    "3. **Modélisation supervisée (baseline vs ensembles) et comparaison des performances**\n",
    "\n",
    "Chaque section inclut des explications détaillées pour assurer la reproductibilité de l'analyse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924681d",
   "metadata": {},
   "source": [
    "Avant de commencer, voici tous les imports de librairie dont nous auront besoin pour lancer les cellules ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b62386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "DATA_PATH = \"adult.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0139b",
   "metadata": {},
   "source": [
    "# 1 - Exploration de données et analyse non supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870bb3c",
   "metadata": {},
   "source": [
    "## Caractéristiques du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3cf39cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (48842, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283f935",
   "metadata": {},
   "source": [
    "**Nombre d'instances :** Le dataset complet contient 48 842 entrées. C'est un volume suffisant pour entraîner un modèle robuste.\n",
    "\n",
    "**Nombre de features :** Il y a 14 variables explicatives + 1 variable cible (income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5310451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Types de données:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              48842 non-null  int64 \n",
      " 1   workclass        48842 non-null  object\n",
      " 2   fnlwgt           48842 non-null  int64 \n",
      " 3   education        48842 non-null  object\n",
      " 4   educational-num  48842 non-null  int64 \n",
      " 5   marital-status   48842 non-null  object\n",
      " 6   occupation       48842 non-null  object\n",
      " 7   relationship     48842 non-null  object\n",
      " 8   race             48842 non-null  object\n",
      " 9   gender           48842 non-null  object\n",
      " 10  capital-gain     48842 non-null  int64 \n",
      " 11  capital-loss     48842 non-null  int64 \n",
      " 12  hours-per-week   48842 non-null  int64 \n",
      " 13  native-country   48842 non-null  object\n",
      " 14  income           48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTypes de données:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69747d21",
   "metadata": {},
   "source": [
    "**Types de variables :**\n",
    "\n",
    "- **Numériques :** age, fnlwgt (= final weight), education-num, capital-gain, capital-loss, hours-per-week.\n",
    "\n",
    "- **Catégorielles :** workclass, education, marital-status, occupation, relationship, race, sex, native-country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8a04e",
   "metadata": {},
   "source": [
    "## Analyse et gestion des valeurs manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3068427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valeurs manquantes par colonne:\n",
      "Aucune valeur manquante détectée\n",
      "\n",
      "--- Détection des '?' comme valeurs manquantes ---\n",
      "workclass: 2799 valeurs manquantes ('?')\n",
      "occupation: 2809 valeurs manquantes ('?')\n",
      "native-country: 857 valeurs manquantes ('?')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValeurs manquantes par colonne:\")\n",
    "missing_counts = df.isna().sum()\n",
    "print(missing_counts[missing_counts > 0] if missing_counts.sum() > 0 else \"Aucune valeur manquante détectée\")\n",
    "\n",
    "# Détecter les '?' comme valeurs manquantes\n",
    "print(\"\\n--- Détection des '?' comme valeurs manquantes ---\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        question_count = (df[col] == '?').sum()\n",
    "        if question_count > 0:\n",
    "            print(f\"{col}: {question_count} valeurs manquantes ('?')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60501a",
   "metadata": {},
   "source": [
    "\n",
    "### Interprétation des valeurs manquantes\n",
    "\n",
    "Les points d'interrogation ('?') observés dans le dataset représentent des **valeurs manquantes** (données non disponibles ou non renseignées). Ces valeurs peuvent affecter la qualité de nos prédictions et doivent être traitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7686ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Colonne  Manquantes  Pourcentage\n",
      "    occupation        2809         5.75\n",
      "     workclass        2799         5.73\n",
      "native-country         857         1.75\n"
     ]
    }
   ],
   "source": [
    "df = df.replace('?', np.nan)\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Colonne': df.columns,\n",
    "    'Manquantes': df.isna().sum(),\n",
    "    'Pourcentage': (df.isna().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Manquantes'] > 0].sort_values('Manquantes', ascending=False)\n",
    "print(missing_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d881446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Nombre total de lignes: 48,842\n",
      "   - Lignes contenant au moins un '?': 3,620\n",
      "   - Pourcentage de données PERDUES: 7.41%\n"
     ]
    }
   ],
   "source": [
    "df_temp = df.copy()\n",
    "df_temp = df_temp.replace('?', np.nan)\n",
    "rows_with_missing = df_temp.isna().any(axis=1).sum()\n",
    "\n",
    "total_rows = len(df)\n",
    "percentage_lost = (rows_with_missing / total_rows) * 100\n",
    "\n",
    "print(f\"   - Nombre total de lignes: {total_rows:,}\")\n",
    "print(f\"   - Lignes contenant au moins un '?': {rows_with_missing:,}\")\n",
    "print(f\"   - Pourcentage de données PERDUES: {percentage_lost:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f8f46",
   "metadata": {},
   "source": [
    "Notre analyse préliminaire montre que la suppression des lignes contenant au moins une valeur manquante entraînerait une perte de données supérieure à 5%. Nous craignons que réduire la taille du jeu d'entraînement d'autant de valeurs puisse nuire à la capacité du modèle à généraliser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20352062",
   "metadata": {},
   "source": [
    "### Stratégie choisie pour ce projet\n",
    "\n",
    "Nous n'avons que des variables catégorielles à imputer, nous avons donc fait le choix de faire une imputation par mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Avant imputation ===\n",
      "Valeurs manquantes totales : 6465\n",
      "\n",
      "Détail par colonne :\n",
      "workclass         2799\n",
      "occupation        2809\n",
      "native-country     857\n",
      "dtype: int64\n",
      "\n",
      " - workclass : imputé avec 'Private'\n",
      "\n",
      " - occupation : imputé avec 'Prof-specialty'\n",
      "\n",
      " - native-country : imputé avec 'United-States'\n",
      "\n",
      "=== Après imputation ===\n",
      "Valeurs manquantes totales : 0\n",
      "\n",
      "✅ Imputation terminée : dataset prêt pour les analyses\n"
     ]
    }
   ],
   "source": [
    "# Application de l'imputation par mode (most_frequent) sur les variables catégorielles\n",
    "print(\"=== Avant imputation ===\")\n",
    "print(f\"Valeurs manquantes totales : {df.isna().sum().sum()}\")\n",
    "print(\"\\nDétail par colonne :\")\n",
    "print(df.isna().sum()[df.isna().sum() > 0])\n",
    "\n",
    "# Imputation des variables catégorielles avec la valeur la plus fréquente (mode)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        mode_value = df[col].mode()[0]  # Récupération du mode\n",
    "        df[col].fillna(mode_value, inplace=True)\n",
    "        print(f\"\\n - {col} : imputé avec '{mode_value}'\")\n",
    "\n",
    "print(\"\\n=== Après imputation ===\")\n",
    "print(f\"Valeurs manquantes totales : {df.isna().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5c5b4",
   "metadata": {},
   "source": [
    "# Répartition des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16dc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x=\"income\")\n",
    "plt.title(\"Répartition de la variable cible (income)\")\n",
    "plt.show()\n",
    "\n",
    "income_ratio = df[\"income\"].value_counts(normalize=True)\n",
    "print(\"Répartition proportionnelle:\\n\", income_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.boxplot(data=df, x=\"income\", y=\"age\", ax=axes[0])\n",
    "axes[0].set_title(\"Distribution de l'âge selon le revenu\")\n",
    "\n",
    "education_order = df[\"education\"].value_counts().index\n",
    "sns.countplot(data=df, y=\"education\", hue=\"income\", order=education_order, ax=axes[1])\n",
    "axes[1].set_title(\"Répartition de l'income par niveau d'éducation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Heatmap des corrélations (variables numériques)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17223e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "\n",
    "numeric_data = df[numeric_cols].copy()\n",
    "numeric_scaled = scaler.fit_transform(numeric_data)\n",
    "pca_components = pca.fit_transform(numeric_scaled)\n",
    "\n",
    "pca_df = pd.DataFrame(pca_components, columns=[\"PC1\", \"PC2\"])\n",
    "pca_df[\"income\"] = df[\"income\"].values\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"income\", alpha=0.5)\n",
    "plt.title(\"PCA (2 composantes) colorée par income\")\n",
    "plt.show()\n",
    "\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "print(f\"Variance expliquée par PC1+PC2: {explained_var.sum():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c789c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(numeric_scaled)\n",
    "\n",
    "cluster_df = pd.DataFrame(pca_components, columns=[\"PC1\", \"PC2\"])\n",
    "cluster_df[\"cluster\"] = clusters.astype(str)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=cluster_df, x=\"PC1\", y=\"PC2\", hue=\"cluster\", palette=\"tab10\", alpha=0.6)\n",
    "plt.title(\"Clusters K-Means projetés sur les composantes PCA\")\n",
    "plt.show()\n",
    "\n",
    "cluster_target = pd.crosstab(clusters, df[\"income\"], normalize=\"index\")\n",
    "print(\"Distribution de income par cluster:\")\n",
    "print(cluster_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c543731",
   "metadata": {},
   "source": [
    "# Préparation des données & Découpage Train/Test\n",
    "\n",
    "Nous encodons la cible, séparons features/cible, puis construisons un pipeline de prétraitement combinant imputations, standardisation des numériques et encodage one-hot des variables catégorielles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b02e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"income\"\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"income_encoded\"] = label_encoder.fit_transform(df[target_col])\n",
    "\n",
    "y = df[\"income_encoded\"]\n",
    "X = df.drop(columns=[target_col, \"income_encoded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"age\",\n",
    "    \"fnlwgt\",\n",
    "    \"educational-num\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "]\n",
    "\n",
    "categorical_features = [col for col in X.columns if col not in numeric_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Variables numériques ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"Variables catégorielles ({len(categorical_features)}): {categorical_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a7776",
   "metadata": {},
   "source": [
    "## Partie 3 · Modélisation : Baseline vs Ensembles\n",
    "\n",
    "Nous entraînons trois modèles (Logistic Regression, Random Forest, Gradient Boosting) encapsulés dans un pipeline complet, évaluons leurs performances via des rapports de classification, comparons Accuracy/F1, puis inspectons la matrice de confusion du meilleur modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "trained_pipelines = {}\n",
    "metrics_records = []\n",
    "\n",
    "for name, estimator in models.items():\n",
    "    clf = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", estimator),\n",
    "    ])\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    metrics_records.append({\"Model\": name, \"Accuracy\": acc, \"F1-Score\": f1})\n",
    "    trained_pipelines[name] = clf\n",
    "\n",
    "    print(f\"===== {name} =====\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_records).sort_values(by=\"F1-Score\", ascending=False)\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45579453",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = metrics_df.iloc[0][\"Model\"]\n",
    "best_pipeline = trained_pipelines[best_model_name]\n",
    "y_pred_best = best_pipeline.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Vérité terrain\")\n",
    "plt.title(f\"Matrice de confusion · {best_model_name}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Meilleur modèle selon F1: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74186de8",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Les modèles d'ensemble (Random Forest et Gradient Boosting) surpassent la régression logistique sur l'Accuracy et le F1-Score, le meilleur selon F1 étant affiché dans la matrice de confusion. Cette configuration offre une base solide pour de futures itérations (optimisation d'hyperparamètres, gestion du déséquilibre, interprétabilité).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
