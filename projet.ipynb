{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70c21d4",
   "metadata": {},
   "source": [
    "# Adult Income Classification Project\n",
    "\n",
    "Le projet vise à analyser le jeu de données Adult Income afin d’identifier les différents facteurs qui influencent le niveau de revenu d'une personne et de construire un modèle capable de prédire si une personne gagne plus ou moins de 50 000 dollars par an. \n",
    "\n",
    "Le dataset, disponible dans plusieurs versions (UCI, OpenML, variantes nettoyées ou simplifiées), est ici utilisé dans sa version OpenML, qui offre un format homogène et des variables à la fois numériques et catégorielles. Notre problème sera approché sous la forme d'une classification binaire (+ ou - de 50k$/an de revenus) car le dataset ne contient pas la valeur exacte du revenu, qu'une catégorie.\n",
    "\n",
    "Ce notebook sera articulé en trois grandes parties :\n",
    "\n",
    "1. **Exploration des données (EDA) et analyses non supervisées**\n",
    "2. **Préprocessing des données et séparation des jeux d'apprentissage/test**\n",
    "3. **Modélisation supervisée (baseline vs ensembles) et comparaison des performances**\n",
    "\n",
    "Chaque section inclut des explications détaillées pour assurer la reproductibilité de l'analyse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924681d",
   "metadata": {},
   "source": [
    "Avant de commencer, voici tous les imports de librairie dont nous auront besoin pour lancer les cellules ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b62386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# Chargement des données depuis une URL pour assurer la reproductibilité\n",
    "DATA_URL = \"https://raw.githubusercontent.com/clemrep/ml-adult-income/refs/heads/main/adult.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0139b",
   "metadata": {},
   "source": [
    "# 1 - Exploration de données et analyse non supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870bb3c",
   "metadata": {},
   "source": [
    "## Caractéristiques du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_URL)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283f935",
   "metadata": {},
   "source": [
    "**Nombre d'instances :** Le dataset complet contient 48 842 entrées. C'est un volume suffisant pour entraîner un modèle robuste.\n",
    "\n",
    "**Nombre de features :** Il y a 14 variables explicatives + 1 variable cible (income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTypes de données:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69747d21",
   "metadata": {},
   "source": [
    "**Types de variables :**\n",
    "\n",
    "- **Numériques :** age, fnlwgt (= final weight), education-num, capital-gain, capital-loss, hours-per-week.\n",
    "\n",
    "- **Catégorielles :** workclass, education, marital-status, occupation, relationship, race, sex, native-country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70ca42",
   "metadata": {},
   "source": [
    "## Split des données de test/entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49707e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"income\"\n",
    "X = df.drop(columns=[target_col])\n",
    "label_encoder = LabelEncoder() \n",
    "\n",
    "y = label_encoder.fit_transform(df[target_col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Données d'entraînement : {X_train.shape}\")\n",
    "print(f\"Données de test (mises de côté) : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f456353",
   "metadata": {},
   "source": [
    "On utilise l'argument stratify pour garantir que la proportion des classes (ici 75% de ≤ 50K et 25% de > 50K) reste strictement la même dans le jeu d'entraînement et le jeu de test. On verra le détail de ces chiffres dans l'analyse exploratoire du dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8a04e",
   "metadata": {},
   "source": [
    "## Analyse et gestion des valeurs manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3068427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValeurs manquantes par colonne:\")\n",
    "missing_counts = X_train.isna().sum()\n",
    "print(missing_counts[missing_counts > 0] if missing_counts.sum() > 0 else \"Aucune valeur manquante détectée\")\n",
    "\n",
    "# Détecter les '?' comme valeurs manquantes\n",
    "print(\"\\n--- Détection des '?' comme valeurs manquantes ---\")\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == 'object':\n",
    "        question_count = (X_train[col] == '?').sum()\n",
    "        if question_count > 0:\n",
    "            print(f\"{col}: {question_count} valeurs manquantes ('?')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60501a",
   "metadata": {},
   "source": [
    "\n",
    "### Interprétation des valeurs manquantes\n",
    "\n",
    "Les points d'interrogation ('?') observés dans le dataset représentent des **valeurs manquantes** (données non disponibles ou non renseignées). Ces valeurs peuvent affecter la qualité de nos prédictions et doivent être traitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace('?', np.nan)\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Colonne': X_train.columns,\n",
    "    'Manquantes': X_train.isna().sum(),\n",
    "    'Pourcentage': (X_train.isna().sum() / len(X_train) * 100).round(2)\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Manquantes'] > 0].sort_values('Manquantes', ascending=False)\n",
    "print(missing_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d881446",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temp = X_train.copy()\n",
    "X_train_temp = X_train_temp.replace('?', np.nan)\n",
    "rows_with_missing = X_train_temp.isna().any(axis=1).sum()\n",
    "\n",
    "total_rows = len(X_train)\n",
    "percentage_lost = (rows_with_missing / total_rows) * 100\n",
    "\n",
    "print(f\"   - Nombre total de lignes: {total_rows:,}\")\n",
    "print(f\"   - Lignes contenant au moins un '?': {rows_with_missing:,}\")\n",
    "print(f\"   - Pourcentage de données PERDUES: {percentage_lost:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f8f46",
   "metadata": {},
   "source": [
    "Notre analyse préliminaire montre que la suppression des lignes contenant au moins une valeur manquante entraînerait une perte de données supérieure à 5%. Nous craignons que réduire la taille du jeu d'entraînement d'autant de valeurs puisse nuire à la capacité du modèle à généraliser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20352062",
   "metadata": {},
   "source": [
    "### Stratégie choisie pour ce projet\n",
    "\n",
    "Nous n'avons que des variables catégorielles à imputer, nous avons donc fait le choix de faire une imputation par mode. Nous allons faire une imputation manuelle pour les données utilisées dans la phase exploratoire puis dans une pipeline pour la phase d'entainement/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On travaille sur une copie de X_train pour l'analyse (EDA)\n",
    "X_train_eda = X_train.copy()\n",
    "\n",
    "# Application de l'imputation par mode (most_frequent) sur les variables catégorielles\n",
    "print(\"=== Avant imputation ===\")\n",
    "print(f\"Valeurs manquantes totales : {X_train.isna().sum().sum()}\")\n",
    "print(\"\\nDétail par colonne :\")\n",
    "print(X_train.isna().sum()[X_train.isna().sum() > 0])\n",
    "\n",
    "# Imputation des variables catégorielles avec la valeur la plus fréquente (mode)\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if X_train[col].isna().sum() > 0:\n",
    "        mode_value = X_train[col].mode()[0]  # Récupération du mode\n",
    "        X_train[col].fillna(mode_value, inplace=True)\n",
    "        print(f\"\\n - {col} : imputé avec '{mode_value}'\")\n",
    "\n",
    "print(\"\\n=== Après imputation ===\")\n",
    "print(f\"Valeurs manquantes totales : {X_train.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5c5b4",
   "metadata": {},
   "source": [
    "## Analyse des distributions\n",
    "\n",
    "Cette section examine la répartition des valeurs pour chaque variable du dataset, ce qui permet de :\n",
    "- Comprendre la forme des distributions\n",
    "- Identifier les déséquilibres dans les variables catégorielles\n",
    "- Détecter d'éventuels patterns ou anomalies dans les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae743c8c",
   "metadata": {},
   "source": [
    "### Distribution des variables numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2270d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des variables numériques\n",
    "numeric_cols = X_train_eda.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].hist(X_train_eda[col], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f\"Distribution de {col}\", fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel(\"Fréquence\")\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c86cc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Observations :**\n",
    "- **age** : Distribution uniforme, pic 30-40 ans (population active)\n",
    "- **fnlwgt** : Poids démographique Census (~200k). Candidate à la suppression (pondération statistique, non prédictive)\n",
    "- **educational-num** : Concentré 9-10 (HS-grad/Some-college)\n",
    "- **capital-gain/loss** : ~95% de zéros, valeurs élevées rares → discriminant pour hauts revenus\n",
    "- **hours-per-week** : Pic à 40h (temps plein), quelques extrêmes (>60h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91318f",
   "metadata": {},
   "source": [
    "### Distribution des variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85047296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des principales variables catégorielles à visualiser\n",
    "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender']\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    value_counts = X_train_eda[col].value_counts()\n",
    "    axes[idx].barh(value_counts.index, value_counts.values, color='coral', edgecolor='black')\n",
    "    axes[idx].set_title(f\"Distribution de {col}\", fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(\"Fréquence\")\n",
    "    axes[idx].invert_yaxis()\n",
    "    \n",
    "    # Afficher les pourcentages\n",
    "    for i, v in enumerate(value_counts.values):\n",
    "        axes[idx].text(v + max(value_counts.values)*0.01, i, f'{v} ({v/len(X_train_eda)*100:.1f}%)', \n",
    "                       va='center', fontsize=9)\n",
    "\n",
    "# Masquer le dernier subplot s'il est vide\n",
    "if len(categorical_cols) < len(axes):\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c596d7",
   "metadata": {},
   "source": [
    "**Observations :**\n",
    "- **workclass** : Private dominant (~75%), Self-employed ~10%, secteur public ~15%\n",
    "- **education** : HS-grad et Some-college majoritaires, Bachelors ~16%, Masters ~5%\n",
    "- **marital-status** : Married-civ-spouse ~45%, Never-married ~35% → très prédictif (doubles revenus)\n",
    "- **occupation** : Distribution équilibrée, Prof-specialty et Craft-repair dominants\n",
    "- **relationship** : Husband ~40%, Not-in-family ~26% → Risque colinéarité avec marital-status\n",
    "- **race** : White ~85%, Black ~10% → Variable sensible (biais potentiels)\n",
    "- **gender** : Male ~67%, Female ~33% → Variable sensible (biais de genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23776ae7",
   "metadata": {},
   "source": [
    "## Distributions, Outliers & Préparation\n",
    "\n",
    "**Variables \"tail-heavy\" (asymétrie forte) :**\n",
    "- capital-gain/loss : ~95% zéros, valeurs élevées rares (>20k$)\n",
    "- fnlwgt : Longue queue droite\n",
    "- hours-per-week : Centrée 40h, extrêmes >80h\n",
    "\n",
    "**Échelles hétérogènes :**\n",
    "- fnlwgt : 10k-1M (x100) | capital-gain/loss : 0-100k$ (x1000) | age : 17-90\n",
    "\n",
    "Cela nécessite une normalisation pour éviter domination artificielle dans les algorithmes à distance/gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4da141",
   "metadata": {},
   "source": [
    "### Détection des Outliers : Isolation Forest\n",
    "\n",
    "**Choix :** Isolation Forest pour détecter anomalies multidimensionnelles\n",
    "- Adapté aux distributions asymétriques\n",
    "- Aucune hypothèse sur la distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Sélection des variables numériques pour la détection d'outliers\n",
    "numeric_cols_for_outliers = ['age', 'fnlwgt', 'educational-num', \n",
    "                              'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "# Création d'un subset sans valeurs manquantes pour l'analyse\n",
    "df_numeric = X_train_eda[numeric_cols_for_outliers].copy()\n",
    "\n",
    "# Remplacement des '?' par NaN si présents (bien que peu probable pour les numériques)\n",
    "# Supprimer les lignes avec NaN pour Isolation Forest\n",
    "df_numeric_clean = df_numeric.dropna()\n",
    "\n",
    "print(f\"Dataset pour détection d'outliers: {df_numeric_clean.shape[0]} observations\")\n",
    "\n",
    "# Isolation Forest avec contamination=0.05 (on estime 5% d'outliers)\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42, n_jobs=-1)\n",
    "outlier_predictions = iso_forest.fit_predict(df_numeric_clean)\n",
    "\n",
    "# -1 = outlier, 1 = inlier\n",
    "n_outliers = (outlier_predictions == -1).sum()\n",
    "outlier_percentage = (n_outliers / len(outlier_predictions)) * 100\n",
    "\n",
    "print(f\"\\nRésultats de la détection d'outliers:\")\n",
    "print(f\"   - Outliers détectés: {n_outliers} ({outlier_percentage:.2f}%)\")\n",
    "print(f\"   - Inliers (normaux): {(outlier_predictions == 1).sum()} ({100-outlier_percentage:.2f}%)\")\n",
    "\n",
    "# Analyse des caractéristiques des outliers\n",
    "df_numeric_clean['is_outlier'] = outlier_predictions == -1\n",
    "outlier_summary = df_numeric_clean.groupby('is_outlier')[numeric_cols_for_outliers].mean()\n",
    "\n",
    "print(\"\\nComparaison Inliers vs Outliers (moyennes):\")\n",
    "print(outlier_summary.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1ba95",
   "metadata": {},
   "source": [
    "**Interprétation des moyennes :**\n",
    "\n",
    "Les outliers présentent des profils distincts révélant leur nature :\n",
    "- **Age +9 ans** (47 vs 38) → Population plus mature\n",
    "- **capital-gain x26** (12,440$ vs 480$) → Revenus de capitaux élevés\n",
    "- **capital-loss x44** (1,221$ vs 28$) → Pertes en capital significatives\n",
    "- **hours-per-week +5h** (45 vs 40) → Plus d'heures travaillées\n",
    "\n",
    "Cependant, ces outliers représentent des profils réels (cadres seniors, investisseurs) et non des erreurs de mesure.\n",
    "\n",
    "**Méthode de gestion : Conservation + atténuation**\n",
    "\n",
    "1. **Pas de suppression** : Profils légitimes, informations utiles pour le modèle\n",
    "2. **Atténuation automatique via StandardScaler** : Ramène valeurs extrêmes vers 0, réduit leur influence\n",
    "3. **Robustesse intrinsèque** : Random Forest/Gradient Boosting tolèrent naturellement les outliers (splits binaires, pas de calculs de distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f85b3d",
   "metadata": {},
   "source": [
    "## Etude de la distribution de la variable cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16dc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x=\"income\")\n",
    "plt.title(\"Répartition de la variable cible (income)\")\n",
    "plt.show()\n",
    "\n",
    "income_ratio = df[\"income\"].value_counts(normalize=True)\n",
    "print(\"Répartition proportionnelle:\\n\", income_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227909f",
   "metadata": {},
   "source": [
    "Sur ce graphique de répartition de la variable income, on observe 75% de <=50K contre 25% de >50K. Le dataset est donc déséquilibré. L'accuracy serait un indicateur biaisé car un modèle pourrait obtenir un score élevé en ignorant simplement la classe minoritaire. Pour y remédier, nous évaluerons nos modèles via le F1-Score et la courbe Precision-Recall, qui sont plus représentatifs de la performance sur la classe minoritaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795570b7",
   "metadata": {},
   "source": [
    "## Feature corrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X_train_eda.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "corr_matrix = X_train_eda[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Heatmap des corrélations (variables numériques)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d688e9",
   "metadata": {},
   "source": [
    "**Analyse de la heatmap :**\n",
    "- Aucune corrélation forte entre variables numériques (max = 0.14 entre educational-num et hours-per-week)\n",
    "- capital-gain et capital-loss légèrement anti-corrélés (-0.03) : indépendants\n",
    "- fnlwgt quasi-indépendant de toutes les autres variables (≈ 0)\n",
    "\n",
    "Cependant, on observe que les variables **education** (catégorielle) et **educational-num** (numérique) encodent la même information (niveau d'éducation). Vérifions cette redondance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la correspondance education <-> educational-num\n",
    "education_mapping = df.groupby('education')['educational-num'].unique().sort_index()\n",
    "print(\"Correspondance education → educational-num:\")\n",
    "for edu, nums in education_mapping.items():\n",
    "    print(f\"  {edu:20s} → {nums}\")\n",
    "\n",
    "# Chaque niveau d'éducation correspond à un seul nombre unique\n",
    "print(f\"\\nNombre de valeurs uniques : education={df['education'].nunique()}, educational-num={df['educational-num'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d19284",
   "metadata": {},
   "source": [
    "**Conclusion :** Chaque modalité de `education` correspond à un unique nombre dans `educational-num`. Ces deux variables encodent donc la même information de manière redondante. Nous supprimons `education` car :\n",
    "- **educational-num** est directement utilisable par les modèles (numérique, ordinal)\n",
    "- **education** nécessiterait un encodage one-hot (augmentation dimensionnalité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2625271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de 'education' (redondante avec 'educational-num')\n",
    "X_train_eda = X_train_eda.drop(columns=['education'])\n",
    "print(f\"Variable 'education' supprimée. Nouvelles dimensions: {X_train_eda.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e080292",
   "metadata": {},
   "source": [
    "Il faudra également retirer education des jeux de données x_train et x_test dans le pré-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a086e9",
   "metadata": {},
   "source": [
    "## Réduction de dimension (PCA)\n",
    "\n",
    "**Objectifs :**\n",
    "1. **Visualisation** : Projeter les données multidimensionnelles en 2D pour observer la séparabilité des classes (>50K vs ≤50K)\n",
    "2. **Réduction de la dimensionnalité** : Atténuer la \"malédiction de la dimensionnalité\" en identifiant les directions de variance maximale\n",
    "3. **Détection de patterns** : Identifier si les revenus élevés se regroupent naturellement dans l'espace réduit\n",
    "\n",
    "La PCA transforme les 6 variables numériques en 2 composantes principales orthogonales, maximisant la variance expliquée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17223e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la PCA sur les variables numériques\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "\n",
    "# On utilise X_train_eda qui contient uniquement les features\n",
    "numeric_data = X_train_eda[numeric_cols].copy() \n",
    "numeric_scaled = scaler.fit_transform(numeric_data)\n",
    "pca_components = pca.fit_transform(numeric_scaled)\n",
    "\n",
    "pca_df = pd.DataFrame(pca_components, columns=[\"PC1\", \"PC2\"])\n",
    "\n",
    "# CORRECTIF : On utilise y_train au lieu de chercher dans X_train_eda\n",
    "# On décode les 0/1 pour avoir un affichage propre dans la légende\n",
    "pca_df[\"income\"] = label_encoder.inverse_transform(y_train)\n",
    "\n",
    "# Visualisation de la projection PCA\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"income\", alpha=0.4, palette=\"Set1\")\n",
    "plt.title(\"Projection PCA (2D) des variables numériques (Train Set)\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%} de variance)\", fontsize=12)\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%} de variance)\", fontsize=12)\n",
    "plt.legend(title=\"Revenu\", loc='upper right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "print(f\"Variance expliquée par PC1: {explained_var[0]:.2%}\")\n",
    "print(f\"Variance expliquée par PC2: {explained_var[1]:.2%}\")\n",
    "print(f\"Variance totale expliquée (PC1+PC2): {explained_var.sum():.2%}\")\n",
    "\n",
    "# Analyse des loadings (contribution des variables originales)\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=numeric_cols\n",
    ")\n",
    "print(\"\\n=== Loadings (contribution des variables) ===\")\n",
    "print(loadings.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455486c",
   "metadata": {},
   "source": [
    "**Interprétation PCA :**\n",
    "- **Variance expliquée** : Les 2 premières composantes capturent ~40-50% de la variance totale (typique pour des données réelles hétérogènes)\n",
    "- **Séparabilité des classes** : Chevauchement important entre les deux groupes de revenus → Pas de séparation linéaire évidente en 2D\n",
    "- **Loadings** : Identifient les variables les plus influentes sur chaque composante (capital-gain/loss et age généralement dominants)\n",
    "\n",
    "**Conclusion** : La PCA révèle que le problème n'est pas linéairement séparable dans l'espace des variables numériques seules. Les variables catégorielles (marital-status, occupation, education) seront cruciales pour la prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8a3cf",
   "metadata": {},
   "source": [
    "## Clustering Non Supervisé (K-Means)\n",
    "\n",
    "**Objectif** : Découvrir des groupes naturels dans les données numériques et évaluer leur correspondance avec les niveaux de revenus. Si les clusters corrèlent avec la cible, ils peuvent devenir une feature informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détermination du nombre optimal de clusters : Elbow Method\n",
    "inertias = []\n",
    "K_range = range(2, 8)  # Testé de 2 à 7 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_temp.fit(numeric_scaled)\n",
    "    inertias.append(kmeans_temp.inertia_)\n",
    "\n",
    "# Visualisation Elbow Method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Nombre de clusters (K)', fontsize=12)\n",
    "plt.ylabel('Inertie (Within-Cluster Sum of Squares)', fontsize=12)\n",
    "plt.title('Elbow Method - Détermination du K optimal', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identification du K optimal (observation visuelle du \"coude\")\n",
    "optimal_k = 3  # Choix basé sur l'observation du coude dans le graphique\n",
    "print(f\"K optimal sélectionné : {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c789c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application K-Means avec K optimal\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(numeric_scaled)\n",
    "\n",
    "print(f\"K-Means appliqué avec K={optimal_k}\")\n",
    "print(f\"Taille des clusters : {np.bincount(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ee1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des clusters sur la projection PCA\n",
    "cluster_df = pd.DataFrame(pca_components, columns=[\"PC1\", \"PC2\"])\n",
    "cluster_df[\"cluster\"] = clusters.astype(str)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(data=cluster_df, x=\"PC1\", y=\"PC2\", hue=\"cluster\", palette=\"Set2\", alpha=0.5, s=50)\n",
    "plt.title(f\"Clusters K-Means (K={optimal_k}) projetés sur PCA\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"PC1\", fontsize=12)\n",
    "plt.ylabel(\"PC2\", fontsize=12)\n",
    "plt.legend(title=\"Cluster\", loc='upper right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad0b19",
   "metadata": {},
   "source": [
    "**Interprétation :**\n",
    "\n",
    "Cette analyse confirme que les variables numériques seules sont insuffisantes pour la prédiction. Les variables catégorielles (marital-status, occupation, etc.) seront cruciales dans notre modèle supervisé. Nous n'ajoutons pas les clusters comme feature pour éviter le data leakage.\n",
    "\n",
    "L'Elbow Method identifie K=3 comme nombre optimal de clusters. La visualisation sur PCA révèle que les groupes naturels dans les données numériques ne correspondent pas directement aux niveaux de revenus (chevauchement important). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24367931",
   "metadata": {},
   "source": [
    "## Synthèse de l'exploration et orientations pour la modélisation\n",
    "\n",
    "**Principaux constats :**\n",
    "- **Dataset** : 48 842 observations, 14 features (6 numériques, 8 catégorielles), déséquilibre de classe (75% ≤50K / 25% >50K)\n",
    "- **Valeurs manquantes** : ~7% de lignes concernées (workclass, occupation, native-country) → imputation par mode pour préserver les données\n",
    "- **Redondances** : Variable `education` supprimée (doublon de `educational-num`)\n",
    "- **Séparabilité** : PCA et clustering révèlent un chevauchement important entre classes → les variables catégorielles (marital-status, occupation) seront cruciales\n",
    "\n",
    "**Stratégie de prétraitement retenue :**\n",
    "1. **Pipeline intégré** : Imputation + standardisation (numériques) + encodage one-hot (catégorielles)\n",
    "2. **Conservation des outliers** : Profils légitimes (cadres, investisseurs), atténués par StandardScaler\n",
    "3. **Métrique d'évaluation** : F1-Score (adapté au déséquilibre de classe)\n",
    "\n",
    "L'exploration confirme la nécessité d'utiliser des modèles d'ensemble capables de capturer des interactions non linéaires entre variables numériques et catégorielles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c543731",
   "metadata": {},
   "source": [
    "# Préparation des données\n",
    "\n",
    "Nous encodons la cible, séparons features/cible, puis construisons un pipeline de prétraitement combinant imputations, standardisation des numériques et encodage one-hot des variables catégorielles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484736bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de la variable 'education' (redondante avec 'educational-num')\n",
    "X_train = X_train.drop(columns=['education'])\n",
    "X_test = X_test.drop(columns=['education'])\n",
    "\n",
    "print(f\"Variable 'education' supprimée des jeux d'entraînement et de test\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"age\",\n",
    "    \"fnlwgt\",\n",
    "    \"educational-num\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "]\n",
    "\n",
    "categorical_features = [col for col in X_train.columns if col not in numeric_features]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Variables numériques ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"Variables catégorielles ({len(categorical_features)}): {categorical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a7776",
   "metadata": {},
   "source": [
    "# 3 - Modélisation : Baseline vs Ensembles\n",
    "\n",
    "**Évaluation Baseline avec Validation Croisée**\n",
    "\n",
    "Pour éviter le data snooping, nous utilisons la validation croisée sur `X_train` uniquement. \n",
    "Le jeu de test `X_test` est conservé pour l'évaluation finale après le tuning des hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "trained_pipelines = {}\n",
    "metrics_records = []\n",
    "\n",
    "# Évaluation avec validation croisée sur X_train uniquement (pas de data snooping)\n",
    "print(\"=== Évaluation Baseline avec Validation Croisée (5 folds) ===\\n\")\n",
    "\n",
    "for name, estimator in models.items():\n",
    "    clf = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", estimator),\n",
    "    ])\n",
    "    \n",
    "    # Validation croisée avec scoring='f1_weighted' (adapté au déséquilibre)\n",
    "    cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "    \n",
    "    # Entraînement sur tout X_train pour conserver le pipeline\n",
    "    clf.fit(X_train, y_train)\n",
    "    trained_pipelines[name] = clf\n",
    "    \n",
    "    mean_cv = cv_scores.mean()\n",
    "    std_cv = cv_scores.std()\n",
    "    \n",
    "    metrics_records.append({\n",
    "        \"Model\": name, \n",
    "        \"CV F1-Weighted Mean\": mean_cv, \n",
    "        \"CV F1-Weighted Std\": std_cv\n",
    "    })\n",
    "    \n",
    "    print(f\"===== {name} =====\")\n",
    "    print(f\"CV F1-Weighted: {mean_cv:.4f} (+/- {std_cv:.4f})\")\n",
    "    print(f\"Scores par fold: {cv_scores}\")\n",
    "    print()\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_records).sort_values(by=\"CV F1-Weighted Mean\", ascending=False)\n",
    "print(\"\\n=== Résumé des performances Baseline ===\")\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45579453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification du meilleur modèle baseline\n",
    "best_model_name = metrics_df.iloc[0][\"Model\"]\n",
    "print(f\"Meilleur modèle baseline: {best_model_name}\")\n",
    "print(f\"CV F1-Weighted Mean: {metrics_df.iloc[0]['CV F1-Weighted Mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf7a9e",
   "metadata": {},
   "source": [
    "Les résultats de la validation croisée confirment la supériorité des modèles d'ensemble (Gradient Boosting et Random Forest) sur la régression logistique pour ce dataset. La faible variance des scores entre les folds (Std < 0.005) démontre la robustesse de notre pipeline de prétraitement et la pertinence de l'échantillonnage stratifié. Le Gradient Boosting est sélectionné pour l'optimisation des hyperparamètres car il offre le meilleur compromis entre précision et rappel (F1-score de 0.86)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c81283",
   "metadata": {},
   "source": [
    "## 4 - Hyperparameter Tuning\n",
    "\n",
    "Sélection du meilleur modèle baseline et optimisation de ses hyperparamètres via GridSearchCV. Cette étape de tuning teste 270 combinaisons de réglages pour optimiser le modèle. Bien que ce processus soit long, il est indispensable pour gagner en précision et obtenir des performances nettement supérieures au modèle par défaut.\n",
    "\n",
    "Attention : cette cellule peut prendre 10 à 30 minutes à s'exécuter. C'est un temps long mais nécessaire afin d'améliorer la qualité des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection du meilleur modèle baseline pour le tuning\n",
    "best_baseline_name = metrics_df.iloc[0][\"Model\"]\n",
    "best_baseline_estimator = models[best_baseline_name]\n",
    "\n",
    "print(f\"Modèle sélectionné pour le tuning: {best_baseline_name}\\n\")\n",
    "\n",
    "# Définition des grilles d'hyperparamètres selon le modèle\n",
    "if best_baseline_name == \"Gradient Boosting\":\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'model__subsample': [0.8, 1.0]\n",
    "    }\n",
    "elif best_baseline_name == \"Random Forest\":\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [200, 300, 400],\n",
    "        'model__max_depth': [10, 20, None],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "else:  # Logistic Regression\n",
    "    param_grid = {\n",
    "        'model__C': [0.1, 1.0, 10.0, 100.0],\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs', 'liblinear']\n",
    "    }\n",
    "\n",
    "# Création du pipeline avec le meilleur modèle\n",
    "tuning_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", best_baseline_estimator),\n",
    "])\n",
    "\n",
    "# GridSearchCV avec 5 folds et scoring='f1_weighted'\n",
    "print(\"=== Démarrage du GridSearchCV ===\")\n",
    "print(f\"Grille d'hyperparamètres: {param_grid}\\n\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    tuning_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Meilleurs hyperparamètres trouvés ===\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\nMeilleur score CV (F1-Weighted): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Conservation du meilleur modèle\n",
    "best_tuned_model = grid_search.best_estimator_\n",
    "\n",
    "# Modèle sélectionné pour le tuning: Gradient Boosting\n",
    "\n",
    "# === Démarrage du GridSearchCV ===\n",
    "# Grille d'hyperparamètres: {'model__n_estimators': [100, 200, 300], 'model__max_depth': [3, 5, 7], 'model__learning_rate': [0.01, 0.1, 0.2], 'model__subsample': [0.8, 1.0]}\n",
    "\n",
    "# Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
    "\n",
    "# === Meilleurs hyperparamètres trouvés ===\n",
    "# {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 200, 'model__subsample': 1.0}\n",
    "\n",
    "# Meilleur score CV (F1-Weighted): 0.8700"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6cfa36c5",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5df4a2",
   "metadata": {},
   "source": [
    "## 5 - Évaluation Finale & Interprétation\n",
    "\n",
    "Évaluation du modèle optimisé sur le jeu de test `X_test` (conservé jusqu'à présent).\n",
    "Génération du rapport de classification, matrice de confusion et analyse de l'importance des features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c0a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur le jeu de test\n",
    "y_pred_test = best_tuned_model.predict(X_test)\n",
    "\n",
    "# Métriques de performance\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"=== Évaluation sur le jeu de test ===\")\n",
    "print(f\"Accuracy: {acc_test:.4f}\")\n",
    "print(f\"F1-Score: {f1_test:.4f}\\n\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, \n",
    "            yticklabels=label_encoder.classes_,\n",
    "            cbar_kws={'label': 'Nombre d\\'observations'})\n",
    "plt.xlabel(\"Prédictions\", fontsize=12)\n",
    "plt.ylabel(\"Vérité terrain\", fontsize=12)\n",
    "plt.title(f\"Matrice de confusion · {best_baseline_name} (tuné)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction de l'importance des features\n",
    "# Note: Seuls Random Forest et Gradient Boosting ont feature_importances_\n",
    "if hasattr(best_tuned_model.named_steps['model'], 'feature_importances_'):\n",
    "    # Récupération du preprocessor déjà fitté depuis le pipeline\n",
    "    fitted_preprocessor = best_tuned_model.named_steps['preprocessor']\n",
    "    \n",
    "    # Récupération des noms de features après preprocessing\n",
    "    # Pour les features numériques\n",
    "    numeric_feature_names = numeric_features\n",
    "    \n",
    "    # Pour les features catégorielles (après OneHotEncoder)\n",
    "    # Le preprocessor est déjà fitté, donc on peut extraire les noms\n",
    "    categorical_transformer = fitted_preprocessor.named_transformers_['cat']\n",
    "    ohe = categorical_transformer.named_steps['onehot']\n",
    "    categorical_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    # Combinaison de tous les noms de features\n",
    "    all_feature_names = list(numeric_feature_names) + list(categorical_feature_names)\n",
    "    \n",
    "    # Extraction des importances\n",
    "    importances = best_tuned_model.named_steps['model'].feature_importances_\n",
    "    \n",
    "    # Création d'un DataFrame pour faciliter le tri et la visualisation\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': all_feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Affichage des top 20 features\n",
    "    top_n = 20\n",
    "    top_features = feature_importance_df.head(top_n)\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=top_features, y='Feature', x='Importance', palette='viridis')\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title(f'Top {top_n} Features par Importance · {best_baseline_name}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n=== Top 10 Features par Importance ===\")\n",
    "    print(top_features.head(10).to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(f\"Le modèle {best_baseline_name} ne fournit pas d'importance des features.\")\n",
    "    print(\"Pour Logistic Regression, considérez l'analyse des coefficients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bebd2d",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "**Résultats obtenus :**\n",
    "- Modèles d'ensemble (RF, GB) surpassent généralement Logistic Regression sur ce problème de classification binaire.\n",
    "- L'optimisation des hyperparamètres améliore les performances par rapport aux modèles baseline.\n",
    "- Les features les plus importantes (capital-gain, age, relationship, etc.) sont cohérentes avec les attentes économiques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
